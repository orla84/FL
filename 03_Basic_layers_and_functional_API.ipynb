{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic layers\n",
    "\n",
    "We only used Dense (or fully connected) layers so far, but they are only part of the story. \n",
    "Here are a few basic layers (also check the Keras [documentation](https://keras.io/layers/core/)) widely used by the DL community:\n",
    "\n",
    "- **Dense**(N_neurons): the standard fully connected layer \n",
    "- **Conv2D**(N_filters, kernel_size): the basic Convolutional layer, where *N_filters* learnable filters of size *(kernel_size x kernel_size)* are convolved across an image. More on this on the computer vision classes\n",
    "- **Dropout**(rate): this ia a regularizer. People realised that overfitting can be avoided by randomly setting a fraction *rate* of connected inputs to 0 during training\n",
    "- **MaxPooling2D**(pool_size=(2, 2)): reduces resolution of the input by a factor of two (takes brightest of 4 pixels)\n",
    "- **LSTM**(N_units): recurrent layers for time series (see e.g. this [explanation](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)), where the output is reused as part of the input, to retain a memory. Think about reading a sentence, the brain remembers previous words to make sense of the currently read word...\n",
    "\n",
    "we will build a model with them so that we can print a summary, and that gives us a better feeling of what they do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/keras_tutorial/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 50)        1400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8450)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8450)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                169020    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 5, 4)              0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10)                600       \n",
      "=================================================================\n",
      "Total params: 171,020\n",
      "Trainable params: 171,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Conv2D, MaxPooling2D, Flatten, Dropout, Dense, Reshape, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer( input_shape=(28,28,3) )) # RGB 28x28 images\n",
    "model.add(Conv2D(50, 3)) # kernel_size is typically 2,3, or 5 in most models\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(20))\n",
    "\n",
    "'''an LSTM takes a time series as input so let's change\n",
    "the current 20-dim vectors shape=(20) into 5 timesteps\n",
    "of of 4-dim vectors shape=(5,4)'''\n",
    "model.add(Reshape((5,4)))\n",
    "model.add(LSTM(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional API and networks with multiple inputs\n",
    "Sequential() is not the only way to build Keras networks: a more flexible way is provided by the functional API. Let's build two new identical models (call them m1 and m2) using in two ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using functional API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.summary()\n",
    "m2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beautiful thing about the functional API is its flexibility: let's build a more complex network like the one in the figure\n",
    "\n",
    "![](nn2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert python code below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
