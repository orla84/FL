{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST classifier\n",
    "\n",
    "##### MNIST dataset\n",
    "Let's first of all have a look at the data: how does a datapoint look like? What's the shape? How do the lables look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import train/test data and print their shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now import matplotlib and print a datapoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing the data\n",
    "Now that we know how the data looks like we want to put them in a useful format for our model. Let's print some numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "0 255\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(np.min(train_images), np.max(train_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to change a few things here:\n",
    "- make the input data 1D\n",
    "- normalize\n",
    "- we want the network to output probabilities that each image corresponds to a given number: this means the labels need to be categorically encoded ( that is 0->[1,0,0,...],  1->[0,1,0...], etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to 1D data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make labels categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build the neural network\n",
    "Now we 784-dim vectors to be used as input of our network, and 10-dim labels to be compared with its output: let's build a network that is able to handle such transformation, with an input layer that takes 784 numbers, an intermediate layer with a lower number of neurons, and a final layer of 10 neurons corresponding to the desired 10-dim output of probabilities. Also let's learn something new, and talk about activations (check [link](https://keras.io/activations/)): these are functions to be applied to the raw output of a layer, typically to introduce some non-linearity in the network. In our case we need at least a **softmax** activation, to transform the final output into a set of probabilities, but we will also use the simple **relu** activation (max(0,x)) for our intermediate layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert python code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did earlier, in order to train/run the model we need to compile it. We need to provide an **optimizer** and the **loss function** it will optimize ('categorical_crossentropy' being a classic for classification tasks), but we can also provide some metrics to monitor our traing, like the accuracy of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert python code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally ready to train. For those who have noticed that no validation set has been reserved, Keras also does that for you and we will set it directly into the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert python code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results: accuracy, loss, overfitting\n",
    "Now we can use the history that we saved to plot accuracies and losses during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert python code below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert python code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing and predicting\n",
    "Once we are happy  with how the model works for the validation test, we can of course run it on the test set, to check the final model performance. Here we do that, and we also show how to use the trained model for a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally predict the probabilities for a test image (remember you need a batch, so slice properly...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
